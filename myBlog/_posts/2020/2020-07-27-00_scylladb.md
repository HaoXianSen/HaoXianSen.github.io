---
title: scylladbå…³æ³¨ç‚¹
tags: scylladb
key: 112
article_header:
  type: cover
  image:
    src: https://user-images.githubusercontent.com/8369671/88509097-ef3d9280-d012-11ea-8821-877702f23406.png
---

# Overview
æœ€è¿‘çœ‹åˆ°scylladbçš„ä¸å…¶ä»–dbçš„æ¯”è¾ƒæ–‡æ¡£æ¯”è¾ƒå…¨é¢, å…¶ä¸­ä¸cassandraå¯¹æ¯”æ›´æ˜¯è¶…å‡ºä¸€æˆª, æ‰€ä»¥è¿‡æ¥çœ‹çœ‹,

å…¶æ˜¯åŸºäºC++ seastar<sup>9,10</sup>é‡å†™çš„column-base nosql, å®ç°äº†CAPä¸­çš„AP,
- masterless, hash ringæ˜¯P
- replication_factorå’ŒWAL commit logæ˜¯A, å› æ­¤at least one, æ‰€ä»¥ä¸èƒ½åšåˆ°C

![image](https://user-images.githubusercontent.com/8369671/88890629-79386600-d274-11ea-8143-0daf1c770a49.png)
> CAP theorem

# Version
- scylladb, 4.1.2
- scylla-monitoring, 3.4.2

# Architect
## read and write flow 
![image](https://user-images.githubusercontent.com/8369671/88525458-32a4fa80-d02d-11ea-966f-dce5263bcb5c.png)
> read and write flow, credit: intel

è™šçº¿è¡¨ç¤ºread opåœ¨`key cache`æ²¡æœ‰å‘½ä¸­, æ­¤æ—¶ä¼šæœç´¢partition summaryæ¥ç¡®å®špartition index, indexé€šè¿‡compression offset mapå®šä½dataåœ¨sstableçš„ä½ç½®<sup>15</sup>

## partitioning
![image](https://user-images.githubusercontent.com/8369671/88526954-2de14600-d02f-11ea-92a1-e0d2ef2d096b.png)
> a hash ring to find necessary nodes<sup>5</sup>
å½“æ‰©ç¼©å®¹nodeæ—¶, æ•´ä¸ªæ‹“æ‰‘ç»“æ„ä¼šå‘ç”Ÿå˜åŒ–, æ­¤æ—¶ä¼šè§¦å‘è‡ªåŠ¨rebalance

æ•°æ®çš„å€¾æ–œä¸å¦, å–å†³äºhash(key)çš„å‡åŒ€åº¦

PRIMARY KEYæœ‰2ä¸ªä½œç”¨,
1. partition keys of the table lets you group rows on the same replica set, determines where data is stored on a given node in the cluster, æŒ‡å®šèŠ‚ç‚¹
2. clustering columns control how those `rows` are stored on the replica/node, åœ¨step1çš„æŒ‡å®šèŠ‚ç‚¹ä¸Šçš„æ•°æ®å­˜å‚¨

> PRIMARY KEY ((a, b), c, d) : a and b compose the partition key, and c is the clustering column.

## mapping

scylladb | mysql
---- | ----
cluster | instance
keyspace | database
table | table
type | è‡ªå®šä¹‰æ•°æ®ç±»å‹

## AddOn 
Scylla Manager & Scylla Monitoring Stack
ç›‘æ§å„ä¸ªèŠ‚ç‚¹, æŸ¥çœ‹é›†ç¾¤

![image](https://user-images.githubusercontent.com/8369671/88510862-73454980-d016-11ea-92e7-2dccb912ff29.png)
> overview, credit: scylladb

![image](https://user-images.githubusercontent.com/8369671/88789201-07efa900-d1c9-11ea-9560-ef3ab4d40d69.png)
> overview2, port usage, credit: scylladb

![image](https://user-images.githubusercontent.com/8369671/88511383-480f2a00-d017-11ea-82ff-09f58eddb44f.png)
> ingest from batch and streaming<sup>2</sup>

# Install
## scylladb
ä¸‹é¢æ ¹æ®ç›¸å…³æ­¥éª¤, æ¥setupä¸€ä¸ªç®€å•çš„cluster,

0. å‡†å¤‡, create `docker-compose.yml` with following content,
    ```shell
    version: '3'
    
    services:
      some-scylla:
        image: scylladb/scylla
        container_name: some-scylla
    
      some-scylla2:
        image: scylladb/scylla
        container_name: some-scylla2
        command: --seeds=some-scylla
    
      some-scylla3:
        image: scylladb/scylla
        container_name: some-scylla3
        command: --seeds=some-scylla
    ```
    å•Š, ğŸ˜¤, å¦‚æœç”¨composeçš„è¯, scyllaåœ¨prometheusæ˜¯upä¸èµ·æ¥çš„, æ‰€ä»¥è¿˜æ˜¯è€è€å®å®å›å½’best practiceçš„æ­¥éª¤<sup>5</sup>
    ![image](https://user-images.githubusercontent.com/8369671/88785802-3d45c800-d1c4-11ea-97d7-f12efc42f95a.png)
    > failed with cmopose
    
    å³,
    ```shell
    docker run --name some-scylla scylladb/scylla
    docker run --name some-scylla2 scylladb/scylla --seeds="$(docker inspect --format='{{ .NetworkSettings.IPAddress }}' some-scylla)"
    docker run --name some-scylla3 scylladb/scylla --seeds="$(docker inspect --format='{{ .NetworkSettings.IPAddress }}' some-scylla)"
    ```
    ![image](https://user-images.githubusercontent.com/8369671/88787205-18525480-d1c6-11ea-86bd-7bf5f87e072c.png)
    > passed with single-command
     
0. å¯åŠ¨
    - `docker-compose up -d`
0. æ£€æŸ¥
    - `docker exec -it some-scylla scylla --version`
    - `docker logs some-scylla | tail`
    - nodetool
        - `docker exec -it some-scylla nodetool status`
        - `docker exec -it some-scylla nodetool describecluster`, æŸ¥çœ‹é›†ç¾¤ä¿¡æ¯
        - `docker exec -it some-scylla nodetool help`
    - cqlsh
        - `docker exec -it some-scylla cqlsh`
        - `describe tables;`
        - `select * from system_schema.scylla_tables limit 13;`
    - æŸ¥çœ‹/ä¿®æ”¹é›†ç¾¤é…ç½®
    - `docker exec -it some-scylla grep --color 'cluster' /etc/scylla/scylla.yaml`
    - `docker exec -it some-scylla /bin/bash`
    - `docker exec -it some-scylla cqlsh UPDATE system.local SET cluster_name = 'my_cluster' where key='local';`


## monitoring
0. download
    ```shell
    wget https://github.com/scylladb/scylla-monitoring/archive/scylla-monitoring-3.4.2.tar.gz
    tar -xvf scylla-monitoring-3.4.2.tar.gz
    cd scylla-monitoring-scylla-monitoring-3.4.2
    ```
0. å‡†å¤‡, create `scylla-monitoring-scylla-monitoring-3.4.2/prometheus/scylla_servers.yml`
    ```shell
    - targets:
            - 172.17.0.2:9180
            - 172.17.0.3:9180
            - 172.17.0.4:9180
      labels:
           cluster: 'Test Cluster'
           dc: datacenter1
    ```
    é…ç½®valueè¦å¯¹å·å…¥åº§, Use the nodetool to validate them
0. å¯åŠ¨
    - å½“åœ¨[mac](https://github.com/scylladb/scylla-monitoring/issues/313#issuecomment-380192083)å¯åŠ¨æ—¶, ä¼šæ‰¾ä¸åˆ°`readlink`, æ‰€ä»¥å°†ä¸‹é¢çš„commandåŠ åˆ°`start-all.sh`çš„å¤´
        - `alias readlink=greadlink`
    - `sh start-all.sh`
0. æ£€æŸ¥
    - `http://localhost:3000/`
    ![image](https://user-images.githubusercontent.com/8369671/88889353-8c4a3680-d272-11ea-9501-9a66b09a9f57.png)
0. æ•°æ®è®¿é—®
    ```shell
    docker exec -it some-scylla cqlsh
    CREATE KEYSPACE my_keyspace WITH replication = {'class':'SimpleStrategy', 'replication_factor' : 3};
    USE my_keyspace;
    CREATE TABLE students (id int PRIMARY KEY, name text, courses map<text, double>);
    
    DESCRIBE KEYSPACE my_keyspace;
    DESCRIBE TABLE students;
    
    INSERT INTO students (id, name, courses) VALUES (1, 'å¼ ä¸‰', {'è¯­æ–‡': 71.1, 'æ•°å­¦': 82, 'è‹±è¯­': 93.3});
    INSERT INTO students (id, name, courses) VALUES (2, 'æå››', {'è¯­æ–‡': 91.1, 'æ•°å­¦': 82, 'è‹±è¯­': 73.3});
    select * from students;
    ```
    ![image](https://user-images.githubusercontent.com/8369671/88889119-2fe71700-d272-11ea-93a5-064e0a626e4a.png)


## manager
- å®‰è£…
    - å¯ä»¥é€šè¿‡dockeræ¥[å®‰è£…](https://hub.docker.com/r/scylladb/scylla-manager)
- åŠŸèƒ½
    - ä¸€ä¸ªé›†ç¾¤ç®¡ç†ç³»ç»Ÿ, é€šè¿‡å¥¹å¯ä»¥ä½¿ç”¨CLIæ¥handleä¸€ç³»åˆ—task<sup>8</sup>

## benchmark
### cassandra-stress<sup>13</sup>
åœ¨å‰é¢setupäº†ä¸€ä¸ª3èŠ‚ç‚¹çš„cluster, ä¸ºäº†ä½¿ç”¨è¿™ä¸ªbm tool, å¦èµ·ä¸€ä¸ªæ–°çš„clusterä¸ºäº†ä¸ä¹‹éš”ç¦»,
0. new bm cluster
    - `docker run --name some-scylla-bm-only -d scylladb/scylla`
0. enter bm cluster
    - `docker exec -it some-scylla-bm-only /bin/bash`
0. run bm cmd
    - å†™
        - `cassandra-stress write n=1000000 -rate threads=64 -node 172.17.0.2 -graph file=graph.html title=awesome revision=bm-write`
        - `cassandra-stress write no-warmup n=1000000 -rate threads=64 -node 172.17.0.2 -graph file=graph.html title=awesome revision=bm-no_warmup_write`
    - è¯»
        - `cassandra-stress read n=1000000 -rate threads=64 -node 172.17.0.2 -graph file=graph.html title=awesome revision=bm-read`
        - `cassandra-stress read no-warmup n=1000000 -rate threads=64 -node 172.17.0.2 -graph file=graph.html title=awesome revision=bm-no_warmup_read`
    - æ··åˆ
        - `cassandra-stress mixed ratio\(write=1,read=1\) n=1000000 -rate threads=64 -node 172.17.0.2 -graph file=graph.html title=awesome revision=bm-mixed`
        - `cassandra-stress mixed ratio\(write=1,read=1\) no-warmup n=1000000 -rate threads=64 -node 172.17.0.2 -graph file=graph.html title=awesome revision=bm-no_warmup_mixed`

![image](https://user-images.githubusercontent.com/8369671/88947113-a90e5a80-d2c2-11ea-9b60-a35017c25533.png)
> write

![image](https://user-images.githubusercontent.com/8369671/88947164-bcb9c100-d2c2-11ea-9a9e-d0f20fbb2594.png)
> read

![image](https://user-images.githubusercontent.com/8369671/88947193-c7745600-d2c2-11ea-999d-c28b6ec87d70.png)
> mixed

### scylla-bench<sup>14</sup>
go clientçº§åˆ«çš„benchmarkå·¥å…·,
0. install
    - `go get github.com/scylladb/scylla-bench`
0. run bm cmd
    - `scylla-bench -workload sequential -mode write -nodes 127.0.0.1:9042`
        ```shell
        mode write
        Results
        Time (avg):	 4m33.860611808s
        Total ops:	 1000000
        Total rows:	 1000000
        Operations/s:	 3746.9349633592005
        Rows/s:		 3746.9349633592005
        Latency:
          max:		 1.160773631s
          99.9th:	 21.037055ms
          99th:		 10.813439ms
          95th:		 6.750207ms
          90th:		 5.439487ms
          median:	 2.949119ms
          mean:		 3.464229ms        
        ```
    - `scylla-bench -workload sequential -mode read -nodes 127.0.0.1:9042`
        ```shell
        mode read
        Results
        Time (avg):	 4m11.740969357s
        Total ops:	 1000000
        Total rows:	 1000000
        Operations/s:	 3972.3625839390193
        Rows/s:		 3972.3625839390193
        Latency:
          max:		 1.015545855s
          99.9th:	 21.626879ms
          99th:		 12.124159ms
          95th:		 7.766015ms
          90th:		 6.324223ms
          median:	 3.473407ms
          mean:		 4.024346ms
        ```
    - å› ä¸ºè¿™ä¸ªbm cmdæˆ‘æ˜¯è¿è¡Œåœ¨host, æ‰€ä»¥docker run some-scyllaæ—¶, æˆ‘åŠ ä¸Šäº† `-p 9042:9042`

## connector
### spark batch writer/reader<sup>16</sup>
```scala
"org.apache.spark"   %% "spark-sql"                 % "3.0.0",
"com.datastax.spark" %% "spark-cassandra-connector" % "2.5.1",
"joda-time"          % "joda-time"                  % "2.10.6",
```

```scala
package io.github.chenfh5.scylladb
import com.datastax.spark.connector._
import org.apache.spark.SparkConf
import org.apache.spark.sql.{SaveMode, SparkSession}

object SparkExample {

  private val keyspaceName = "my_keyspace"
  private val tableName = "students"
  private val scylladbHostIP = "127.0.0.1"

  private val ss = {
    val conf = new SparkConf()
    conf.set("spark.app.name", "scylladb_writer_test")
    conf.set("spark.master", "local[1]")
    conf.set("spark.cassandra.connection.host", scylladbHostIP)
    SparkSession.builder().config(conf).getOrCreate()
  }
  import ss.implicits._

  def scan(): Unit = {
    val rdd = ss.sparkContext.cassandraTable(keyspaceName, tableName)
    rdd.take(11).foreach(println)
  }

  def writer(): Unit = {
    val df = ss.sparkContext
      .parallelize((10 to 13).map(i =>
        (i, "æˆ‘çš„åå­—æ˜¯%d".format(i), Map("è¯­æ–‡" -> (i + 0.1), "æ•°å­¦" -> (i + 0.2), "spark" -> (i + 0.3)))))
      .toDF("id", "name", "courses")

    df.show()
    df.write
      .format("org.apache.spark.sql.cassandra")
      .option("keyspace", keyspaceName)
      .option("table", tableName)
      .mode(SaveMode.Append)
      .save()
  }

  def read(): Unit = {
    val df = ss.read
      .format("org.apache.spark.sql.cassandra")
      .option("keyspace", keyspaceName)
      .option("table", tableName)
      .load
      .filter("id > 2")
      .select("id", "name", "courses")

    df.show(11, truncate = false)
  }

  def main(args: Array[String]): Unit = {
    println("begin")
    scan()
    writer()
    read()
    println("end")
  }

}
```

### flink streaming writer<sup>17</sup>
```scala
"org.apache.flink" %% "flink-streaming-scala"     % "1.11.1",
"org.apache.flink" %% "flink-clients"             % "1.11.1",
"org.apache.flink" %% "flink-connector-cassandra" % "1.11.1",
```

```scala
package io.github.chenfh5.scylladb

import org.apache.flink.streaming.api.TimeCharacteristic
import org.apache.flink.streaming.api.scala.{StreamExecutionEnvironment, _}
import org.apache.flink.streaming.connectors.cassandra.CassandraSink

import scala.collection.JavaConverters._
object FlinkExample {

  private val keyspaceName = "my_keyspace"
  private val tableName = "students"
  private val scylladbHostIP = "127.0.0.1"

  def writer(): Unit = {
    val env = StreamExecutionEnvironment.getExecutionEnvironment
    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
    env.setParallelism(1)

    val source =
      env.fromCollection((20 to 25).map(i =>
        (i, "æˆ‘çš„åå­—æ˜¯%d".format(i), Map("è¯­æ–‡" -> (i + 0.1), "æ•°å­¦" -> (i + 0.2), "flink" -> (i + 0.3)).asJava))) // need convert scala to java pojo

    val result = source.filter(e => e._1 < 24).keyBy(_._1)

    CassandraSink
      .addSink(result)
      .setQuery("INSERT INTO %s.%s(id, name, courses) values (?, ?, ?);".format(keyspaceName, tableName))
      .setHost(scylladbHostIP)
      .build()

    result.print().setParallelism(1)
    env.execute()
  }

  def main(args: Array[String]): Unit = {
    println("begin")
    writer()
    println("end")
  }

}
```

### golang reader<sup>18</sup>
ç±»ä¼¼äºscylla-bench<sup>14</sup>çš„`DoReadsFromTable()`æˆ–è€…`DoScanTable()`
```golang
package main

import (
    "fmt"

    "github.com/gocql/gocql"
)

const (
    keyspaceName   = "my_keyspace"
    tableName      = "students"
    scylladbHostIP = "127.0.0.1"
)

func main() {
    // connect to the cluster
    cluster := gocql.NewCluster(scylladbHostIP)
    cluster.Keyspace = keyspaceName
    session, _ := cluster.CreateSession()
    defer session.Close()

    // define schema
    var id int
    var name string
    var courses map[string]float64
    
    // list records
    iter := session.Query(fmt.Sprintf("SELECT id, name, courses FROM %s where token(id) <= ? LIMIT 10", tableName), "12").Iter()
    for iter.Scan(&id, &name, &courses) {
        fmt.Println("student:", id, name, courses)
    }
    if err := iter.Close(); err != nil {
        fmt.Println(err)
    }
}
```

# Reference
0. [scylladb](https://www.scylladb.com/)
0. [Turning messy data into a gold mine using Spark, Flink, and ScyllaDB](https://www.dynamicyield.com/article/turning-messy-data-into-a-gold-mine/)
0. [Making NoSQL Databases Persistent-Memory-Aware: The Apache Cassandra* Example](https://software.intel.com/content/www/us/en/develop/articles/making-nosql-databases-persistent-memory-aware-the-apache-cassandra-example.html)
0. [Scylla Download Center](https://www.scylladb.com/download/?platform=docker)
0. [Best Practices for Running Scylla on Docker](https://docs.scylladb.com/operating-scylla/procedures/tips/best_practices_scylla_on_docker/#id15)
0. [docker hub scylladb doc](https://hub.docker.com/r/scylladb/scylla)
0. [install monitoring](https://docs.scylladb.com/operating-scylla/monitoring/3.4/monitoring_stack/#install-scylla-monitoring)
0. [manager CLI](https://docs.scylladb.com/operating-scylla/manager/2.1/sctool/#cluster-add)
0. [å¼‚æ­¥ç¼–ç¨‹æ¡†æ¶Seastarä»‹ç»](https://zhuanlan.zhihu.com/p/30738569)
0. [ç°ä»£ç¡¬ä»¶ä¸Šçš„é«˜æ€§èƒ½Cï¼‹å¼‚æ­¥æ¡†æ¶-SeaStar](https://cloud.tencent.com/developer/news/270650#:~:text=Seastar%E6%98%AF%E4%B8%80%E4%B8%AA%E5%9F%BA%E4%BA%8E%E5%88%86,%E5%92%8C%E4%BD%8E%E5%BB%B6%E8%BF%9F%E7%9A%84%E7%9B%AE%E6%A0%87%E3%80%82)
0. [ScyllaDBè°ƒç ”åˆ†æ](https://blog.csdn.net/mytobaby00/article/details/80375196)
0. [é€šç”¨é«˜æ•ˆçš„æ•°æ®ä¿®å¤æ–¹æ³•ï¼šRow level repair](https://www.infoq.cn/article/8rleTIWSBo2Y7MpfsMlW)
0. [cassandra-stress](https://docs.datastax.com/en/dse/6.0/dse-admin/datastax_enterprise/tools/toolsCStress.html)
0. [scylla-bench](https://github.com/scylladb/scylla-bench)
0. [How Cassandra reads and writes data](https://docs.datastax.com/en/archived/cassandra/3.0/cassandra/dml/dmlAboutReads.html)
0. [spark-cassandra-connector](https://github.com/datastax/spark-cassandra-connector#documentation)
0. [Flink Cassandra Connector](https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/connectors/cassandra.html)
0. [Scylla Go Driver](https://github.com/scylladb/gocql)
