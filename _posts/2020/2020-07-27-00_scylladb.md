---
title: scylladb关注点
tags: scylladb
key: 112
article_header:
  type: cover
  image:
    src: https://user-images.githubusercontent.com/8369671/88509097-ef3d9280-d012-11ea-8821-877702f23406.png
---

# Overview
最近看到scylladb的与其他db的比较文档比较全面, 其中与cassandra对比更是超出一截, 所以过来看看,

其是基于C++ seastar<sup>9,10</sup>重写的column-base nosql, 实现了CAP中的AP,
- masterless, hash ring是P
- replication_factor和WAL commit log是A, 因此at least one, 所以不能做到C

![image](https://user-images.githubusercontent.com/8369671/88890629-79386600-d274-11ea-8143-0daf1c770a49.png)
> CAP theorem

# Version
- scylladb, 4.1.2
- scylla-monitoring, 3.4.2

# Architect
## read and write flow 
![image](https://user-images.githubusercontent.com/8369671/88525458-32a4fa80-d02d-11ea-966f-dce5263bcb5c.png)
> read and write flow, credit: intel

虚线表示read op在`key cache`没有命中, 此时会搜索partition summary来确定partition index, index通过compression offset map定位data在sstable的位置<sup>15</sup>

## partitioning
![image](https://user-images.githubusercontent.com/8369671/88526954-2de14600-d02f-11ea-92a1-e0d2ef2d096b.png)
> a hash ring to find necessary nodes<sup>5</sup>
当扩缩容node时, 整个拓扑结构会发生变化, 此时会触发自动rebalance

数据的倾斜与否, 取决于hash(key)的均匀度

PRIMARY KEY有2个作用,
1. partition keys of the table lets you group rows on the same replica set, determines where data is stored on a given node in the cluster, 指定节点
2. clustering columns control how those `rows` are stored on the replica/node, 在step1的指定节点上的数据存储

> PRIMARY KEY ((a, b), c, d) : a and b compose the partition key, and c is the clustering column.

## mapping

scylladb | mysql
---- | ----
cluster | instance
keyspace | database
table | table
type | 自定义数据类型

## AddOn 
Scylla Manager & Scylla Monitoring Stack
监控各个节点, 查看集群

![image](https://user-images.githubusercontent.com/8369671/88510862-73454980-d016-11ea-92e7-2dccb912ff29.png)
> overview, credit: scylladb

![image](https://user-images.githubusercontent.com/8369671/88789201-07efa900-d1c9-11ea-9560-ef3ab4d40d69.png)
> overview2, port usage, credit: scylladb

![image](https://user-images.githubusercontent.com/8369671/88511383-480f2a00-d017-11ea-82ff-09f58eddb44f.png)
> ingest from batch and streaming<sup>2</sup>

# Install
## scylladb
下面根据相关步骤, 来setup一个简单的cluster,

0. 准备, create `docker-compose.yml` with following content,
    ```shell
    version: '3'
    
    services:
      some-scylla:
        image: scylladb/scylla
        container_name: some-scylla
    
      some-scylla2:
        image: scylladb/scylla
        container_name: some-scylla2
        command: --seeds=some-scylla
    
      some-scylla3:
        image: scylladb/scylla
        container_name: some-scylla3
        command: --seeds=some-scylla
    ```
    啊, 😤, 如果用compose的话, scylla在prometheus是up不起来的, 所以还是老老实实回归best practice的步骤<sup>5</sup>
    ![image](https://user-images.githubusercontent.com/8369671/88785802-3d45c800-d1c4-11ea-97d7-f12efc42f95a.png)
    > failed with cmopose
    
    即,
    ```shell
    docker run --name some-scylla scylladb/scylla
    docker run --name some-scylla2 scylladb/scylla --seeds="$(docker inspect --format='{{ .NetworkSettings.IPAddress }}' some-scylla)"
    docker run --name some-scylla3 scylladb/scylla --seeds="$(docker inspect --format='{{ .NetworkSettings.IPAddress }}' some-scylla)"
    ```
    ![image](https://user-images.githubusercontent.com/8369671/88787205-18525480-d1c6-11ea-86bd-7bf5f87e072c.png)
    > passed with single-command
     
0. 启动
    - `docker-compose up -d`
0. 检查
    - `docker exec -it some-scylla scylla --version`
    - `docker logs some-scylla | tail`
    - nodetool
        - `docker exec -it some-scylla nodetool status`
        - `docker exec -it some-scylla nodetool describecluster`, 查看集群信息
        - `docker exec -it some-scylla nodetool help`
    - cqlsh
        - `docker exec -it some-scylla cqlsh`
        - `describe tables;`
        - `select * from system_schema.scylla_tables limit 13;`
    - 查看/修改集群配置
    - `docker exec -it some-scylla grep --color 'cluster' /etc/scylla/scylla.yaml`
    - `docker exec -it some-scylla /bin/bash`
    - `docker exec -it some-scylla cqlsh UPDATE system.local SET cluster_name = 'my_cluster' where key='local';`


## monitoring
0. download
    ```shell
    wget https://github.com/scylladb/scylla-monitoring/archive/scylla-monitoring-3.4.2.tar.gz
    tar -xvf scylla-monitoring-3.4.2.tar.gz
    cd scylla-monitoring-scylla-monitoring-3.4.2
    ```
0. 准备, create `scylla-monitoring-scylla-monitoring-3.4.2/prometheus/scylla_servers.yml`
    ```shell
    - targets:
            - 172.17.0.2:9180
            - 172.17.0.3:9180
            - 172.17.0.4:9180
      labels:
           cluster: 'Test Cluster'
           dc: datacenter1
    ```
    配置value要对号入座, Use the nodetool to validate them
0. 启动
    - 当在[mac](https://github.com/scylladb/scylla-monitoring/issues/313#issuecomment-380192083)启动时, 会找不到`readlink`, 所以将下面的command加到`start-all.sh`的头
        - `alias readlink=greadlink`
    - `sh start-all.sh`
0. 检查
    - `http://localhost:3000/`
    ![image](https://user-images.githubusercontent.com/8369671/88889353-8c4a3680-d272-11ea-9501-9a66b09a9f57.png)
0. 数据访问
    ```shell
    docker exec -it some-scylla cqlsh
    CREATE KEYSPACE my_keyspace WITH replication = {'class':'SimpleStrategy', 'replication_factor' : 3};
    USE my_keyspace;
    CREATE TABLE students (id int PRIMARY KEY, name text, courses map<text, double>);
    
    DESCRIBE KEYSPACE my_keyspace;
    DESCRIBE TABLE students;
    
    INSERT INTO students (id, name, courses) VALUES (1, '张三', {'语文': 71.1, '数学': 82, '英语': 93.3});
    INSERT INTO students (id, name, courses) VALUES (2, '李四', {'语文': 91.1, '数学': 82, '英语': 73.3});
    select * from students;
    ```
    ![image](https://user-images.githubusercontent.com/8369671/88889119-2fe71700-d272-11ea-93a5-064e0a626e4a.png)


## manager
- 安装
    - 可以通过docker来[安装](https://hub.docker.com/r/scylladb/scylla-manager)
- 功能
    - 一个集群管理系统, 通过她可以使用CLI来handle一系列task<sup>8</sup>

## benchmark
### cassandra-stress<sup>13</sup>
在前面setup了一个3节点的cluster, 为了使用这个bm tool, 另起一个新的cluster为了与之隔离,
0. new bm cluster
    - `docker run --name some-scylla-bm-only -d scylladb/scylla`
0. enter bm cluster
    - `docker exec -it some-scylla-bm-only /bin/bash`
0. run bm cmd
    - 写
        - `cassandra-stress write n=1000000 -rate threads=64 -node 172.17.0.2 -graph file=graph.html title=awesome revision=bm-write`
        - `cassandra-stress write no-warmup n=1000000 -rate threads=64 -node 172.17.0.2 -graph file=graph.html title=awesome revision=bm-no_warmup_write`
    - 读
        - `cassandra-stress read n=1000000 -rate threads=64 -node 172.17.0.2 -graph file=graph.html title=awesome revision=bm-read`
        - `cassandra-stress read no-warmup n=1000000 -rate threads=64 -node 172.17.0.2 -graph file=graph.html title=awesome revision=bm-no_warmup_read`
    - 混合
        - `cassandra-stress mixed ratio\(write=1,read=1\) n=1000000 -rate threads=64 -node 172.17.0.2 -graph file=graph.html title=awesome revision=bm-mixed`
        - `cassandra-stress mixed ratio\(write=1,read=1\) no-warmup n=1000000 -rate threads=64 -node 172.17.0.2 -graph file=graph.html title=awesome revision=bm-no_warmup_mixed`

![image](https://user-images.githubusercontent.com/8369671/88947113-a90e5a80-d2c2-11ea-9b60-a35017c25533.png)
> write

![image](https://user-images.githubusercontent.com/8369671/88947164-bcb9c100-d2c2-11ea-9a9e-d0f20fbb2594.png)
> read

![image](https://user-images.githubusercontent.com/8369671/88947193-c7745600-d2c2-11ea-999d-c28b6ec87d70.png)
> mixed

### scylla-bench<sup>14</sup>
go client级别的benchmark工具,
0. install
    - `go get github.com/scylladb/scylla-bench`
0. run bm cmd
    - `scylla-bench -workload sequential -mode write -nodes 127.0.0.1:9042`
        ```shell
        mode write
        Results
        Time (avg):	 4m33.860611808s
        Total ops:	 1000000
        Total rows:	 1000000
        Operations/s:	 3746.9349633592005
        Rows/s:		 3746.9349633592005
        Latency:
          max:		 1.160773631s
          99.9th:	 21.037055ms
          99th:		 10.813439ms
          95th:		 6.750207ms
          90th:		 5.439487ms
          median:	 2.949119ms
          mean:		 3.464229ms        
        ```
    - `scylla-bench -workload sequential -mode read -nodes 127.0.0.1:9042`
        ```shell
        mode read
        Results
        Time (avg):	 4m11.740969357s
        Total ops:	 1000000
        Total rows:	 1000000
        Operations/s:	 3972.3625839390193
        Rows/s:		 3972.3625839390193
        Latency:
          max:		 1.015545855s
          99.9th:	 21.626879ms
          99th:		 12.124159ms
          95th:		 7.766015ms
          90th:		 6.324223ms
          median:	 3.473407ms
          mean:		 4.024346ms
        ```
    - 因为这个bm cmd我是运行在host, 所以docker run some-scylla时, 我加上了 `-p 9042:9042`

## connector
### spark batch writer/reader<sup>16</sup>
```scala
"org.apache.spark"   %% "spark-sql"                 % "3.0.0",
"com.datastax.spark" %% "spark-cassandra-connector" % "2.5.1",
"joda-time"          % "joda-time"                  % "2.10.6",
```

```scala
package io.github.chenfh5.scylladb
import com.datastax.spark.connector._
import org.apache.spark.SparkConf
import org.apache.spark.sql.{SaveMode, SparkSession}

object SparkExample {

  private val keyspaceName = "my_keyspace"
  private val tableName = "students"
  private val scylladbHostIP = "127.0.0.1"

  private val ss = {
    val conf = new SparkConf()
    conf.set("spark.app.name", "scylladb_writer_test")
    conf.set("spark.master", "local[1]")
    conf.set("spark.cassandra.connection.host", scylladbHostIP)
    SparkSession.builder().config(conf).getOrCreate()
  }
  import ss.implicits._

  def scan(): Unit = {
    val rdd = ss.sparkContext.cassandraTable(keyspaceName, tableName)
    rdd.take(11).foreach(println)
  }

  def writer(): Unit = {
    val df = ss.sparkContext
      .parallelize((10 to 13).map(i =>
        (i, "我的名字是%d".format(i), Map("语文" -> (i + 0.1), "数学" -> (i + 0.2), "spark" -> (i + 0.3)))))
      .toDF("id", "name", "courses")

    df.show()
    df.write
      .format("org.apache.spark.sql.cassandra")
      .option("keyspace", keyspaceName)
      .option("table", tableName)
      .mode(SaveMode.Append)
      .save()
  }

  def read(): Unit = {
    val df = ss.read
      .format("org.apache.spark.sql.cassandra")
      .option("keyspace", keyspaceName)
      .option("table", tableName)
      .load
      .filter("id > 2")
      .select("id", "name", "courses")

    df.show(11, truncate = false)
  }

  def main(args: Array[String]): Unit = {
    println("begin")
    scan()
    writer()
    read()
    println("end")
  }

}
```

### flink streaming writer<sup>17</sup>
```scala
"org.apache.flink" %% "flink-streaming-scala"     % "1.11.1",
"org.apache.flink" %% "flink-clients"             % "1.11.1",
"org.apache.flink" %% "flink-connector-cassandra" % "1.11.1",
```

```scala
package io.github.chenfh5.scylladb

import org.apache.flink.streaming.api.TimeCharacteristic
import org.apache.flink.streaming.api.scala.{StreamExecutionEnvironment, _}
import org.apache.flink.streaming.connectors.cassandra.CassandraSink

import scala.collection.JavaConverters._
object FlinkExample {

  private val keyspaceName = "my_keyspace"
  private val tableName = "students"
  private val scylladbHostIP = "127.0.0.1"

  def writer(): Unit = {
    val env = StreamExecutionEnvironment.getExecutionEnvironment
    env.setStreamTimeCharacteristic(TimeCharacteristic.EventTime)
    env.setParallelism(1)

    val source =
      env.fromCollection((20 to 25).map(i =>
        (i, "我的名字是%d".format(i), Map("语文" -> (i + 0.1), "数学" -> (i + 0.2), "flink" -> (i + 0.3)).asJava))) // need convert scala to java pojo

    val result = source.filter(e => e._1 < 24).keyBy(_._1)

    CassandraSink
      .addSink(result)
      .setQuery("INSERT INTO %s.%s(id, name, courses) values (?, ?, ?);".format(keyspaceName, tableName))
      .setHost(scylladbHostIP)
      .build()

    result.print().setParallelism(1)
    env.execute()
  }

  def main(args: Array[String]): Unit = {
    println("begin")
    writer()
    println("end")
  }

}
```

### golang reader<sup>18</sup>
类似于scylla-bench<sup>14</sup>的`DoReadsFromTable()`或者`DoScanTable()`
```golang
package main

import (
    "fmt"

    "github.com/gocql/gocql"
)

const (
    keyspaceName   = "my_keyspace"
    tableName      = "students"
    scylladbHostIP = "127.0.0.1"
)

func main() {
    // connect to the cluster
    cluster := gocql.NewCluster(scylladbHostIP)
    cluster.Keyspace = keyspaceName
    session, _ := cluster.CreateSession()
    defer session.Close()

    // define schema
    var id int
    var name string
    var courses map[string]float64
    
    // list records
    iter := session.Query(fmt.Sprintf("SELECT id, name, courses FROM %s where token(id) <= ? LIMIT 10", tableName), "12").Iter()
    for iter.Scan(&id, &name, &courses) {
        fmt.Println("student:", id, name, courses)
    }
    if err := iter.Close(); err != nil {
        fmt.Println(err)
    }
}
```

# Reference
0. [scylladb](https://www.scylladb.com/)
0. [Turning messy data into a gold mine using Spark, Flink, and ScyllaDB](https://www.dynamicyield.com/article/turning-messy-data-into-a-gold-mine/)
0. [Making NoSQL Databases Persistent-Memory-Aware: The Apache Cassandra* Example](https://software.intel.com/content/www/us/en/develop/articles/making-nosql-databases-persistent-memory-aware-the-apache-cassandra-example.html)
0. [Scylla Download Center](https://www.scylladb.com/download/?platform=docker)
0. [Best Practices for Running Scylla on Docker](https://docs.scylladb.com/operating-scylla/procedures/tips/best_practices_scylla_on_docker/#id15)
0. [docker hub scylladb doc](https://hub.docker.com/r/scylladb/scylla)
0. [install monitoring](https://docs.scylladb.com/operating-scylla/monitoring/3.4/monitoring_stack/#install-scylla-monitoring)
0. [manager CLI](https://docs.scylladb.com/operating-scylla/manager/2.1/sctool/#cluster-add)
0. [异步编程框架Seastar介绍](https://zhuanlan.zhihu.com/p/30738569)
0. [现代硬件上的高性能C＋异步框架-SeaStar](https://cloud.tencent.com/developer/news/270650#:~:text=Seastar%E6%98%AF%E4%B8%80%E4%B8%AA%E5%9F%BA%E4%BA%8E%E5%88%86,%E5%92%8C%E4%BD%8E%E5%BB%B6%E8%BF%9F%E7%9A%84%E7%9B%AE%E6%A0%87%E3%80%82)
0. [ScyllaDB调研分析](https://blog.csdn.net/mytobaby00/article/details/80375196)
0. [通用高效的数据修复方法：Row level repair](https://www.infoq.cn/article/8rleTIWSBo2Y7MpfsMlW)
0. [cassandra-stress](https://docs.datastax.com/en/dse/6.0/dse-admin/datastax_enterprise/tools/toolsCStress.html)
0. [scylla-bench](https://github.com/scylladb/scylla-bench)
0. [How Cassandra reads and writes data](https://docs.datastax.com/en/archived/cassandra/3.0/cassandra/dml/dmlAboutReads.html)
0. [spark-cassandra-connector](https://github.com/datastax/spark-cassandra-connector#documentation)
0. [Flink Cassandra Connector](https://ci.apache.org/projects/flink/flink-docs-release-1.11/dev/connectors/cassandra.html)
0. [Scylla Go Driver](https://github.com/scylladb/gocql)
